#+TITLE: Kaggle Toxic Comments Competition
#+PROPERTY: header-args :session *Python* :results none 

* Overview

https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge


References
- https://github.com/bhargavvader/personal/tree/master/notebooks/text_analysis_tutorial
- https://github.com/skipgram/modern-nlp-in-python/blob/master/executable/Modern_NLP_in_Python.ipynb
- http://ruder.io/deep-learning-nlp-best-practices/index.html
- https://www.oreilly.com/learning/perform-sentiment-analysis-with-lstms-using-tensorflow
- https://www.kaggle.com/jhoward/nb-svm-strong-linear-baseline
- https://stackoverflow.com/questions/41789133/what-are-c-state-and-m-state-in-tensorflow-lstm

* Notes
** <2018-02-07 Wed> Initial look at the data


#+BEGIN_SRC python 
import pandas as pd

data = pd.read_csv('data/train.csv')


data.columns.tolist()
#+END_SRC

#+BEGIN_SRC python

xx = data[['toxic','severe_toxic','obscene','threat', 'insult', 'identity_hate']]
xx =  data.columns.tolist()[2:]

yy = xx.sum(axis=1)
xx[yy > 2]
#+END_SRC

#+BEGIN_EXAMPLE

In [62]: xx.sum()
Out[62]: 
toxic            15294
severe_toxic      1595
obscene           8449
threat             478
insult            7877
identity_hate     1405
dtype: int64

 yy.value_counts()
Out[55]: 
0    143346
1      6360
3      4209
2      3480
4      1760
5       385
6        31
dtype: int64

In [57]: sum(yy > 0)
Out[57]: 16225

In [58]: sum(yy > 0)/data.shape[0]
Out[58]: 0.10167887648758234

In [61]: xx.T.dot(xx)
Out[61]: 
               toxic  severe_toxic  obscene  threat  insult  identity_hate
toxic          15294          1595     7926     449    7344           1302
severe_toxic    1595          1595     1517     112    1371            313
obscene         7926          1517     8449     301    6155           1032
threat           449           112      301     478     307             98
insult          7344          1371     6155     307    7877           1160
identity_hate   1302           313     1032      98    1160           1405

#+END_EXAMPLE


#+BEGIN_SRC python
import spacy

nlp = spacy.load('en')
foo = nlp(data['comment_text'].iloc[0])

for t in foo:
   print("{} {}".format(t.text, t.lemma_))

#+END_SRC

** <2018-02-08 Thu>

Following this example
https://github.com/skipgram/modern-nlp-in-python/blob/master/executable/Modern_NLP_in_Python.ipynb

#+BEGIN_SRC python
import pandas as pd
import spacy


data = pd.read_csv('data/train.csv')
nlp  = spacy.load('en')

def comments_gen(comments):
    for c in comments:
        yield unicode(c,'utf-8')

def keep_token(t):
    return (t.is_alpha and 
            not (t.is_space or t.is_punct or 
                 t.is_stop or t.like_num))

def lematize_comment(comment):
    return [ t.lemma_ for t in comment if keep_token(t)]
            

def lematize_comments(comments):
    docs = []
    for c in nlp.pipe(comments_gen(comments), batch_size=100, n_threads=4):
        docs.append(lematize_comment(c))
    return docs


data_small = data.iloc[0:10000]
docs = lematize_comments(data_small['comment_text'])

#+END_SRC

#+BEGIN_SRC python
from gensim.corpora import Dictionary
from gensim.models.ldamulticore import LdaMulticore
from gensim.models.hdpmodel import HdpModel
from gensim.models.tfidfmodel import TfidfModel
from gensim.matutils import sparse2full

comments_dictionary = Dictionary(docs)
comments_dictionary.filter_extremes(no_below=10, no_above=0.2)
comments_dictionary.compactify()

comments_corpus = [comments_dictionary.doc2bow(d) for d in docs]
comments_tfidf = TfidfModel(comments_corpus)

lda = LdaMulticore(comments_tfidf[comments_corpus],
                   num_topics=20,
                   id2word=comments_dictionary,
                   workers=3)

topic_vecs = [sparse2full(c, lda.num_topics) for c in lda[comments_tfidf[comments_corpus]]]
#+END_SRC


#+BEGIN_SRC python
import numpy as np
from sklearn import svm
from sklearn import metrics

topic_array = np.vstack(topic_vecs)

labels = np.array(data_small['toxic'])


clf = svm.SVC(probability=True, kernel='linear')
clf.fit(topic_array, labels)

predicted = clf.predict(topic_array)
metrics.confusion_matrix(labels, predicted)

#+END_SRC


Classifying based on LDA doesn't seem to work well. Trying classifying on 
words.

#+BEGIN_SRC python

comments_vecs = [sparse2full(c, len(comments_dictionary)) for c in comments_tfidf[comments_corpus]]


clf = svm.SVC(probability=True, kernel='linear')
clf.fit(comments_vecs, labels)

predicted = clf.predict(comments_vecs)
metrics.confusion_matrix(labels, predicted)

#+END_SRC

** <2018-02-11 Sun> Finding descriimitive words

How to find the most descrimitive words? Found this scikit learn
example using a CHI2 test

http://scikit-learn.org/stable/auto_examples/text/document_classification_20newsgroups.html


#+BEGIN_SRC python
from sklearn.feature_selection import SelectKBest, chi2

ch2 = SelectKBest(chi2, k=100)
X_train = ch2.fit_transform(comments_vecs, labels)


clf = svm.SVC(probability=True, kernel='linear')
clf.fit(X_train, labels)

predicted = clf.predict(X_train)
metrics.confusion_matrix(labels, predicted)



[comments_dictionary.id2token[i] for i in ch2.get_support(indices=True)]

xx = [comments_dictionary.id2token[i] for i in ch2.get_support(indices=True)]
aa = [[(t.lemma_, t.vector) for t in nlp(c)] for c in xx]
aa = [nlp(c) for c in xx]

#+END_SRC


#+BEGIN_SRC python
from sklearn.feature_selection import SelectFpr

fpr = SelectFpr(chi2, alpha=0.025)
X_train = fpr.fit_transform(comments_vecs, labels)

clf = svm.SVC(probability=True, kernel='linear')
clf.fit(X_train, labels)

predicted = clf.predict(X_train)
metrics.accuracy_score(labels, predicted)
metrics.f1_score(labels, predicted)
metrics.confusion_matrix(labels, predicted)

xx = [comments_dictionary.id2token[i] for i in fpr.get_support(indices=True)]
aa = [[(t.lemma_, t.vector) for t in nlp(c)] for c in xx]
aa = [nlp(c) for c in xx]


#+END_SRC

#+BEGIN_SRC python

from sklearn.preprocessing import normalize
normed_matrix = normalize(X_train, axis=1, norm='l1')

tmp = []
num_scores = normed_matrix.shape[1]
for i in range(normed_matrix.shape[0]):
    scores = X_train[i,:]
    avgvec = np.sum([aa[j].vector * scores[j] for j in range(num_scores)], axis=0, keepdims=True)

    
#+END_SRC

** <2018-02-12 Mon> Starting to consolidate prototype code

#+BEGIN_SRC python
import numpy as np
import pandas as pd
import spacy

from gensim.corpora import Dictionary
from gensim.models.tfidfmodel import TfidfModel
from gensim.matutils import sparse2full

from sklearn.feature_selection import SelectFpr, chi2

from sklearn import svm
from sklearn import metrics




dataFname = 'data/train.csv'
data = pd.read_csv(dataFname)
labelColnames =  data.columns.tolist()[2:]
data['any']   = data[labelColnames].apply(lambda x: int(any(x)), axis=1)

nlp  = spacy.load('en_core_web_md')

def keep_token(t):
    return (t.is_alpha and 
            not (t.is_space or t.is_punct or 
                 t.is_stop or t.like_num))

def lematize_comment(comment):
    return [ t.lemma_ for t in comment if keep_token(t)]
            

def lematize_comments(comments):
    docs = []
    for c in nlp.pipe(comments, batch_size=100, n_threads=4):
        docs.append(lematize_comment(c))
    return docs


# lemmatize the comments
data_orig = data
data = data.iloc[0:10000]
docs = lematize_comments(data['comment_text'])

# Convert comments into word vectors
comments_dictionary = Dictionary(docs)
comments_dictionary.filter_extremes(no_below=10, no_above=0.3)
comments_dictionary.compactify()

comments_corpus = [comments_dictionary.doc2bow(d) for d in docs]
model_tfidf     = TfidfModel(comments_corpus)
comments_tfidf  = model_tfidf[comments_corpus]
comments_vecs   = [sparse2full(c, len(comments_dictionary)) for c in comments_tfidf]


# Find most descrimitive words for any of the labels
labels = np.array(data['any'])
model_fpr = SelectFpr(chi2, alpha=0.025)
model_fpr.fit(comments_vecs, labels)


# foo here
X_train = model_fpr.transform(comments_vecs)
fpr_tokens = [nlp(t) for t in [comments_dictionary[i] for i in model_fpr.get_support(indices=True)]]
tmp = []
num_scores = X_train.shape[1]
for i in range(X_train.shape[0]):
    scores = X_train[i,:]
    avgvec = np.sum([fpr_tokens[j].vector * scores[j] for j in range(num_scores)], axis=0, keepdims=True)
    tmp.append(avgvec)

X_train = np.vstack(tmp)

clf = svm.SVC(probability=True, kernel='rbf')
clf.fit(X_train, labels)

predicted = clf.predict(X_train)
metrics.accuracy_score(labels, predicted)
metrics.f1_score(labels, predicted)
metrics.confusion_matrix(labels, predicted)

data_test = data_orig[10000:11000]
test_docs = lematize_comments(data_test['comment_text'])
test_corpus = [comments_dictionary.doc2bow(d) for d in test_docs]
test_tfidf  = model_tfidf[test_corpus]
test_vecs   = [sparse2full(c, len(comments_dictionary)) for c in test_tfidf]

X_test = model_fpr.transform(test_vecs)
tmp = []
for i in range(X_test.shape[0]):
    scores = X_test[i,:]
    avgvec = np.sum([fpr_tokens[j].vector * scores[j] for j in range(num_scores)], axis=0, keepdims=True)
    tmp.append(avgvec)
X_test = np.vstack(tmp)


correct = np.array(data_test['any'])
predicted = clf.predict(X_test)

metrics.accuracy_score(correct, predicted)
metrics.f1_score(correct, predicted)
metrics.confusion_matrix(correct, predicted)

#+END_SRC

What about another field?

#+BEGIN_SRC python

categories = ['toxic',
 'severe_toxic',
 'obscene',
 'threat',
 'insult',
 'identity_hate']

models  = {}
for cat in categories:
    labels = data[cat]
    models[cat] = svm.SVC(probability=True, kernel='rbf')
    models[cat].fit(X_train, labels) 

results = []
for cat in categories:
    labels = data[cat]
    predicted = models[cat].predict(X_train)
    results.append({'cat': cat, 
           'accuracy': metrics.accuracy_score(labels, predicted),
           'f1': metrics.f1_score(labels, predicted)})


#+END_SRC


figuring out if data can be written to disk as a csv

#+BEGIN_SRC python

tmp = data.drop(['comment_text'], axis=1)
tmp2 = pd.DataFrame(X_train)
tmp2.rename(columns=lambda x: 'F'+str(x), inplace=True)

tmp3 = pd.concat([tmp, tmp2], axis=1)

#+END_SRC
** <2018-02-18 Sun> Metrics experiment

#+BEGIN_SRC python
tf.reset_default_graph()

ph1 = tf.placeholder(tf.int32, shape=[10,5])
ph2 = tf.placeholder(tf.int32, shape=[10,5])
eq_op = tf.equal(ph1,ph2)
_, acc_op = tf.metrics.accuracy(ph1,ph2)

size_op = tf.size(eq_op)
sum_op = tf.reduce_sum(tf.cast(eq_op, tf.int32))

myacc_op = sum_op / size_op

#diff_op = tf.cast(ph1-ph2,tf.float32)
#fro_op = tf.norm(diff_op, ord=2,axis=0)

x1 = np.random.randint(0,high=2, size=(10,5))
x2 = np.random.randint(0,high=2, size=(10,5))

linit_op = tf.local_variables_initializer()
ginit_op = tf.global_variables_initializer()

sess = tf.InteractiveSession()
sess.run([linit_op, ginit_op])

sess.run(acc_op,feed_dict={ph1: x1, ph2:x1})
sess.run(acc_op,feed_dict={ph1: x1, ph2:x2})
sess.run(eq_op,feed_dict={ph1: x1, ph2:x2})
sess.run(sum_op,feed_dict={ph1: x1, ph2:x2})
sess.run(fro_op,feed_dict={ph1: x1, ph2:x2})

sess.run(myacc_op, feed_dict={ph1: x1, ph2:x1})

#+END_SRC

** <2018-02-21 Wed> Experimenting with custom word embeddings


#+BEGIN_SRC python
import pandas as pd
import spacy

data_full = pd.read_csv('data/train.csv')
nlp       = spacy.load('en')


def keep_token(t):
    return not (t.is_space or t.is_punct or 
                 t.is_stop or t.like_num)

def lematize_comment(comment):
    return [ t.lemma_ for t in comment if keep_token(t)]
            

def lematize_comments(comments):
    docs = []
    for c in nlp.pipe(comments, batch_size=100, n_threads=4):
        docs.append(lematize_comment(c))
    return docs


# lemmatize the comments
data = data_full.iloc[0:10000]
docs = lematize_comments(data['comment_text'])


from gensim.corpora import Dictionary

comments_dictionary = Dictionary(docs)

from gensim.models import Word2Vec

model = Word2Vec(sentences=docs, size=300)
words = list(model.wv.vocab)

xx = [i for i,d in enumerate(docs) if 'f*ck' in d]

#+END_SRC



#+BEGIN_SRC python

import re

foo = [c for c in data['comment_text'] if re.search(r'f\*ck',c)]

foo_dict = Dictionary(foo)

foo_model = Word2Vec(sentences=foo, size=100)

foo_words = list(foo_model.wv.vocab)


cls = spacy.util.get_lang_class('en')
nlp = cls()
xx = [t for t in nlp(foo[1])]


#+END_SRC


#+BEGIN_SRC python
nlp = spacy.load('en', disable=['ner'])
docs = lematize_comments(data['comment_text'])
#+END_SRC

#+BEGIN_SRC python

import gensim.parsing.preprocessing as preprocessing
 dd = preprocessing.preprocess_documents(data['comment_text'].tolist())


CUSTOM_FILTERS = [lambda x: x.lower(), preprocessing.strip_tags, preprocessing.strip_punctuation]
dd = [preprocessing.preprocess_string(c, CUSTOM_FILTERS) for c in data['comment_text']]
   

#+END_SRC


#+BEGIN_SRC python
from gensim.models.phrases import Phrases, Phraser
bigram_transformer = Phraser(Phrases(docs))
model = Word2Vec(bigram_transformer[docs], size=300)

#+END_SRC

Fast text works really well.

#+BEGIN_SRC python
from gensim.models.fasttext import FastText

ft_model = FastText(bigram_transformer[docs], min_count=1, workers=16)

#+END_SRC
** <2018-02-22 Thu> Debugging

Had problems with following data after preprocessing

#+BEGIN_SRC python
comments_text = data['comment_text']
bad= [i for i,c in enumerate(comments_text) if isinstance(c,float)]

#+END_SRC

#+BEGIN_EXAMPLE
[4482,
 17173,
 23529,
 25050,
 25718,
 38313,
 39799,
 43642,
 47072,
 55871,
 57795,
 61758,
 62881,
 71168,
 76734,
 82232,
 82681,
 93867,
 100782,
 122919,
 139976,
 140477,
 146671,
 148563,
 148865,
 151379]
#+END_EXAMPLE

** <2018-02-23 Fri> Debugging RNN inference

Having problems converting test text to vectors using embeddings

#+BEGIN_SRC 
In [320]: 
for i in range(len(comments_text)):
     try:
          text2vecs(comments_text[i], embeddeds, maxwords)
     except ValueError:
          print('Index {} is bad'.format(i))
 
/home/jcardent/local/miniconda3/bin/ipython:60: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).
/home/jcardent/local/miniconda3/bin/ipython:62: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).
Index 34 is bad
Index 114 is bad
Index 819 is bad
Index 1278 is bad
Index 1711 is bad
Index 1762 is bad
Index 2424 is bad
Index 2628 is bad
Index 2887 is bad
Index 3404 is bad
Index 3891 is bad
Index 4075 is bad
Index 4674 is bad
Index 5565 is bad
Index 6171 is bad
Index 6647 is bad
Index 6660 is bad
Index 7322 is bad
Index 7549 is bad
Index 7711 is bad
Index 7805 is bad
Index 9932 is bad
Index 10067 is bad
Index 10783 is bad
Index 10912 is bad
Index 10948 is bad
Index 10988 is bad
Index 11068 is bad
Index 11470 is bad
Index 11873 is bad
Index 12314 is bad
Index 12701 is bad
Index 13412 is bad
Index 14721 is bad
Index 14999 is bad
Index 15232 is bad
Index 15340 is bad
Index 15786 is bad
Index 15889 is bad
Index 16105 is bad
Index 16439 is bad
Index 16903 is bad
Index 17489 is bad
Index 17590 is bad
Index 17788 is bad
Index 18122 is bad
Index 18482 is bad
Index 18721 is bad
Index 18756 is bad
Index 19487 is bad
Index 19747 is bad
Index 21102 is bad
Index 22542 is bad
Index 23632 is bad
Index 23742 is bad
Index 23772 is bad
Index 24622 is bad
Index 25050 is bad
Index 25827 is bad
Index 26582 is bad
Index 27478 is bad
Index 28228 is bad
Index 28247 is bad
Index 29005 is bad
Index 29307 is bad
Index 29397 is bad
Index 29570 is bad
Index 29636 is bad
Index 29935 is bad
Index 30592 is bad
Index 31038 is bad
Index 31461 is bad
Index 31649 is bad
Index 31823 is bad
Index 31990 is bad
Index 32082 is bad
....
#+END_SRC

Looks like all of these are foreign language comments.
** <2018-03-01 Thu> Recreating derived data sets

#+BEGIN_EXAMPLE
jcardent@linux-6m2w:/workspace/projects/kaggle_toxiccomments> python src/learn_chi2.py -t data/derived/train_processed.csv -c models/chi2scores.pkl
Reading data...
Building dictionary...
Creating tfidf model...
Converting to tfidf vectors...
Calculating Chi2 scores...
Saving chi2 scores...
jcardent@linux-6m2w:/workspace/projects/kaggle_toxiccomments> python src/extract_best_fragments.py -i data/derived/train_processed.csv -o data/derived/train_50-0.csv --maxwords 50 --windowsize 0 -c models/chi2scores.pkl
Reading data...
Extracting fragments...
Saving results...
jcardent@linux-6m2w:/workspace/projects/kaggle_toxiccomments> python src/learn_fasttext.py -i data/derived/train_processed.csv -e models/embeddings -w 8
Reading data...
Learning embeddings...
Saving model...
#+END_EXAMPLE
